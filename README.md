# ğŸ’» Laptops Data Analysis Project

[![Python](https://img.shields.io/badge/Python-3.8+-blue?style=flat-square&logo=python)](https://python.org)
[![Pandas](https://img.shields.io/badge/Pandas-Latest-green?style=flat-square&logo=pandas)](https://pandas.pydata.org)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen?style=flat-square)](README.md)

---

## ğŸ“Œ DescripciÃ³n del Proyecto

AnÃ¡lisis y limpieza de datos de laptops usando **Python y pandas** para demostrar habilidades prÃ¡cticas de Data Wrangling y ETL. Ideal para portafolios de trabajo.

### Objetivos Principales
- âœ… Limpieza y transformaciÃ³n de datos reales
- âœ… Manejo de duplicados y valores faltantes
- âœ… AnÃ¡lisis exploratorio: agrupaciÃ³n, ordenamiento, filtrado
- âœ… CÃ³digo reproducible y documentado
- âœ… Ejemplos listos para entrevistas tÃ©cnicas

---

## ğŸ› ï¸ Tech Stack

| TecnologÃ­a | DescripciÃ³n |
|-----------|------------|
| **Python** ğŸ | Lenguaje base |
| **Pandas** ğŸ“Š | ManipulaciÃ³n y anÃ¡lisis de datos |
| **Jupyter Notebook** ğŸ““ | AnÃ¡lisis exploratorio interactivo |
| **Git** ğŸ”€ | Control de versiones |

---

## ğŸ“‚ Estructura del Proyecto

```
Pandas_practique/
â”œâ”€â”€ ğŸ“„ README.md                          # Este archivo
â”œâ”€â”€ ğŸ“„ pyproject.toml                     # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ ğŸ“„ test.py                            # Scripts de prueba
â”œâ”€â”€ ğŸ““ heart_failure.ipynb                # AnÃ¡lisis dataset corazÃ³n
â”œâ”€â”€ ğŸ““ laptop_dataset.ipynb               # AnÃ¡lisis dataset laptops
â”‚
â””â”€â”€ ğŸ“ dataset/
    â”œâ”€â”€ laptop_price.csv                  # ğŸ’¾ Dataset principal (laptops)
    â”œâ”€â”€ heart_failure_clinical_records_dataset.csv
    â””â”€â”€ players_20.csv
```

---

## ğŸš€ Quick Start

### Requisitos Previos
- Python 3.8+
- pip o uv

### InstalaciÃ³n

**1ï¸âƒ£ Clonar/descargar el repositorio**
```bash
git clone https://github.com/tu-usuario/Pandas_practique.git
cd Pandas_practique
```

**2ï¸âƒ£ Crear entorno virtual**
```bash
python -m venv .venv
```

**3ï¸âƒ£ Activar entorno**
```bash
# Windows
.\.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

**4ï¸âƒ£ Instalar dependencias**
```bash
pip install -r requirements.txt
# o
uv sync  # si usas uv (mÃ¡s rÃ¡pido)
```

**5ï¸âƒ£ Ejecutar notebooks o scripts**
```bash
jupyter notebook laptop_dataset.ipynb
# o
python test.py
```

---

## ğŸ“š Conceptos Clave Aprendidos

### 1. Manejo de Duplicados
```python
# Identificar duplicados
dupli_last = df.duplicated('Company', keep='last')

# Eliminar duplicados
df.drop_duplicates(['Company'], keep='first')
```

> âš ï¸ **NOTA IMPORTANTE:** `keep='last'` y `keep='first'` respetan el **orden actual** del DataFrame. Para ordenar por **valor** (ej: precio mÃ¡ximo), debes **ordenar primero** con `sort_values()`.

### 2. Seleccionar Precio MÃ¡ximo/MÃ­nimo por Grupo
```python
# MÃ¡s caro por compaÃ±Ã­a
max_price = df.sort_values(['Company', 'Price_euros'], 
                           ascending=[True, False]) \
             .drop_duplicates('Company', keep='first') \
             [['Company', 'Price_euros']]

# MÃ¡s barato por compaÃ±Ã­a
min_price = df.sort_values(['Company', 'Price_euros'], 
                           ascending=[True, True]) \
             .drop_duplicates('Company', keep='first') \
             [['Company', 'Price_euros']]
```

### 3. Alternativa con GroupBy (MÃ¡s Eficiente) â­
```python
# Obtener Ã­ndice del mÃ¡ximo por grupo
idx = df.groupby('Company')['Price_euros'].idxmax()
most_expensive = df.loc[idx][['Company', 'Price_euros']]

# Obtener Ã­ndice del mÃ­nimo por grupo
idx = df.groupby('Company')['Price_euros'].idxmin()
cheapest = df.loc[idx][['Company', 'Price_euros']]
```

---

## ğŸ¯ Ejemplo PrÃ¡ctico Completo

### Problema
Extraer la laptop **mÃ¡s cara** de cada compaÃ±Ã­a, manteniendo datos ordenados.

### SoluciÃ³n (2 mÃ©todos)

### MÃ©todo A: Sort + Drop Duplicates âœ¨
```python
import pandas as pd

df = pd.read_csv('dataset/laptop_price.csv')

# Ordenar por compaÃ±Ã­a (A-Z) y precio (mayor-menor)
# Luego tomar la primera = la mÃ¡s cara
most_expensive = (
    df.sort_values(['Company', 'Price_euros'], 
                   ascending=[True, False])
      .drop_duplicates(subset='Company', keep='first')
      .reset_index(drop=True)
      [['Company', 'Price_euros']]
)

print(most_expensive)
```

**Ventajas:**
- ğŸ‘ Muy legible y fÃ¡cil de entender
- ğŸ‘ Ideal para explicar en entrevistas

---

### MÃ©todo B: GroupBy + idxmax âš¡
```python
import pandas as pd

df = pd.read_csv('dataset/laptop_price.csv')

# Obtener Ã­ndice de mÃ¡ximo precio por compaÃ±Ã­a
idx = df.groupby('Company')['Price_euros'].idxmax()

# Seleccionar esas filas y ordenar
most_expensive = (
    df.loc[idx]
      .sort_values('Company')
      .reset_index(drop=True)
      [['Company', 'Price_euros']]
)

print(most_expensive)
```

**Ventajas:**
- âš¡ MÃ¡s rÃ¡pido en datasets grandes (millones de filas)
- ğŸ¯ MÃ¡s explÃ­cito en intenciÃ³n

---

## Salida Esperada
```
      Company  Price_euros
0        ASUS          1500
1         Dell          1800
2          HP          1200
...
```

---

## âš™ï¸ Habilidades TÃ©cnicas Demostradas

| Habilidad | DescripciÃ³n |
|-----------|------------|
| ğŸ”„ **ETL** | ExtracciÃ³n, transformaciÃ³n y carga de datos |
| ğŸ“Š **EDA** | AnÃ¡lisis exploratorio de datos |
| ğŸ§¹ **Data Cleaning** | Manejo de duplicados, nulos, outliers |
| ğŸ” **Grouping & Aggregation** | `groupby()`, `agg()`, `pivot_table()` |
| ğŸ“ˆ **Sorting & Filtering** | `sort_values()`, `query()`, `loc[]`, `iloc[]` |
| ğŸ“ **DocumentaciÃ³n** | CÃ³digo limpio, README profesional |

---

## ğŸ’¡ Tips para Entrevistas TÃ©cnicas

### â“ Pregunta tÃ­pica: "Â¿CuÃ¡l es la diferencia entre `drop_duplicates(..., keep='last')` y `groupby().idxmax()`?"

**Respuesta profesional:**

| Aspecto | `drop_duplicates` | `groupby().idxmax()` |
|--------|-------------------|-------------------|
| **Orden** | Respeta orden actual del DF | Define orden explÃ­citamente |
| **Valor** | Requiere sort previo | Busca mÃ¡ximo automÃ¡ticamente |
| **Velocidad** | O(n log n) | O(n) |
| **Legibilidad** | MÃ¡s intuitivo | MÃ¡s explÃ­cito |
| **Caso de uso** | Datos pequeÃ±os-medianos | Datasets masivos |

**ConclusiÃ³n:**
- `keep='last'` respeta el **orden actual** del DataFrame
- Para obtener el valor mÃ¡ximo, **siempre ordena primero** por esa columna
- `groupby().idxmax()` es mÃ¡s **eficiente** y **explÃ­cito** en intenciÃ³n

---

### â“ Pregunta: "Â¿CÃ³mo manejaste los datos duplicados?"

**Estructura de respuesta:**
```
1. âœ… IdentifiquÃ© duplicados con df.duplicated()
2. âœ… AnalicÃ© quÃ© fila mantener (estrategia: mÃ¡s caro, mÃ¡s reciente, etc.)
3. âœ… ApliquÃ© drop_duplicates() con keep= apropiado
4. âœ… ValidÃ© con .shape y sample() despuÃ©s
5. âœ… GenerÃ© reportes de limpieza (ej: "EliminÃ© 250 duplicados de 5000 filas")
```

---

## ğŸ“– Recursos Ãštiles

- ğŸ”— [Pandas Documentation](https://pandas.pydata.org/docs/)
- ğŸ”— [Real Python - Pandas Tutorials](https://realpython.com/learning-paths/pandas-data-science/)
- ğŸ”— [DataCamp - Data Cleaning](https://www.datacamp.com)
- ğŸ”— [Kaggle Datasets](https://www.kaggle.com/datasets)

---

## ğŸ¤ Contribuciones

Este es un proyecto de aprendizaje. Sugerencias y mejoras son bienvenidas.

---

## ğŸ“§ Contacto & Links

- **Email:** tu-email@gmail.com
- **LinkedIn:** [linkedin.com/in/tu-perfil](https://linkedin.com)
- **GitHub:** [github.com/tu-usuario](https://github.com)
- **Portfolio:** [tu-sitio.com](https://tu-sitio.com)

---

## â­ Si te fue Ãºtil, Â¡no olvides dejar una estrella!

```
â­â­â­â­â­  Star this repo si aprendiste algo nuevo
```

---

**Ãšltima actualizaciÃ³n:** Enero 2026 | **Estado:** ğŸŸ¢ Activo | **Version:** 2.0

